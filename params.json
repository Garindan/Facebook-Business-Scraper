{
  "name": "Facebook Business Scraper",
  "tagline": "A Web Scraper for Facebook Business Data | Marketing",
  "body": "# Facebook Business Scraper for Marketing\r\n\r\nA **Facebook scraper** for business intelligence by targeted location. This python scraper can assist in driving various campaigns if you engage in Business-to-Business (B2B) marketing with the following constraint:\r\n\r\n![Sample of Marketing Business Data](https://github.com/Garindan/facebook-business-scraper/raw/master/Sample%20Data.png)\r\n\r\n> You will need to follow Facebook's Terms of Service (ToS), and applicable laws in your region. I or we take no responsibility for the use of this tool.\r\n\r\n### Resources\r\n***\r\n<div align=\"center\" id=\"resources\">\r\n<img alt=\"Project Icon\" src=\"https://github.com/Garindan/facebook-business-scraper/raw/master/Project%20Icon.png\">\r\n\r\n<p align=\"left\">This project is provided to you by Jussive. A local business SEO provider who offers SEO for Google, Managed Hosting, and Website Development options to revise or create content which improves search rates.</p>\r\n\r\n<table>\r\n  <tr>\r\n    <th>Name</th>\r\n    <th>Link</th> \r\n  </tr>\r\n  <tr>\r\n    <td>Website</td> \r\n    <td><a href=\"https://www.jussive.com\" alt=\"Local SEO Service\">https://www.jussive.com</a></td>\r\n  </tr>\r\n  <tr>\r\n    <td>Blog</td>\r\n    <td><a href=\"https://www.jussive.com/b\" alt=\"SEO & SEM Blog\">https://www.jussive.com/b</a></td> \r\n  </tr>\r\n</table>\r\n</div>\r\n\r\n### Installation\r\n***\r\n####Debian and Ubuntu\r\n\r\n**System Packages**\r\n\r\nInstall all required system packages if not already installed\r\n\r\n`apt-get update && apt-get upgrade -y; apt-get install python python-pip python-mysqldb ca-certificates git -y`\r\n\r\n**Python Library's**\r\n\r\nInstall all required Python libraries if not already installed\r\n\r\n`pip install argparse selenium bs4`\r\n\r\n**Simple PhantomJS Installation**\r\n\r\nDownload the latest PhantomJS package and extract\r\n\r\n`cd /tmp; wget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-x86_64.tar.bz2; tar xvfj phantomjs-2.1.1-linux-x86_64.tar.bz2`\r\n\r\nCleanup and create symbolic links\r\n\r\n`rm -rf /tmp/phantomjs-*.tar.bz2; mv phantomjs-2.1.1-linux-x86_64 /opt/phantomjs; ln -sf /opt/phantomjs/bin/phantomjs /usr/local/bin`\r\n\r\n**MySQL Installation and Configuration**\r\n\r\nInstall and Configure MySQL\r\n\r\n`apt-get install mysql-server mysql-client`\r\n\r\nConnect to the database server\r\n\r\n`mysql -u root -p`\r\n\r\nCreate a database to utilize\r\n\r\n`CREATE DATABASE Facebook;`\r\n\r\nCreate the table utilized to store data\r\n\r\n`CREATE TABLE Facebook.business_pages (\r\nid INT NOT NULL AUTO_INCREMENT,\r\nservice VARCHAR(250),\r\npage VARCHAR(250),\r\nname VARCHAR(250),\r\nsearch_location VARCHAR(250),\r\nlocation VARCHAR(250),\r\nwebsite VARCHAR(250),\r\nphone VARCHAR(250),\r\nemail VARCHAR(250),\r\nPRIMARY KEY (id)\r\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;`\r\n\r\nExit the MySQL prompt\r\n\r\n`exit;`\r\n\r\n**Web scraper**\r\n\r\nInstall the Facebook web scraper\r\n\r\n`cd /opt; git clone https://github.com/Garindan/facebook-business-scraper/`\r\n\r\n### Usage\r\n***\r\n\r\n####Modes of Operation\r\n\r\nThe Facebook business scraper comes with two modes of operation (gather or get) which is specified via the command line argument '-m' or '--mode'. \r\n\r\n##### Gather\r\n\r\nThe '**gather**' mode scrapes information for a specific location and service ('-l Miami, Florida' or -'--location Florida'), and stores the Facebook business page in the database for processing. \r\n\r\nNotes: _Facebook may rate limit you for using this method, and providing another account should fix any issues if you start getting minimal results. Should the script error out or stop producing redefine your service lists to include only results you have not processed to avoid database duplicates. Do not forget that you need to comply with Facebook's ToS._\r\n\r\n**Mode: 'gather' Usage Notes**\r\n\r\nA custom service list can be defined by using '--services services.txt' or the script will try to gather all business information for every associated service available. The services file should contain one service per line (the default services.txt file contains all possible services) if utilized.\r\n\r\nThe scroll page command line argument is meant to set memory limitations or to deliver fast results. You'll get  a connection refused if all the available RAM / Memory is used. Typically, you will not need to scroll over 2,000 times for one service if it is for a state.\r\n\r\nFacebook authentication is required for scraping data in this mode\r\n\r\n**Mode: 'gather' Usage Example**\r\n\r\n`python /opt/facebook-business-scraper/main.py --location Florida --mode gather --scroll 10 --services \"/opt/facebook-business-scraper/services.txt\" --dbip 127.0.0.1 --database Facebook --dbuser root --dbpasswd examplepass --fbuser example@hotmail.com --fbpasswd examplepass`\r\n\r\n##### Get\r\n\r\nThe second mode of operation is '**get**', and it will go through all information in the database that has not yet been processed to retrieve business contact information. Database entries that do match your previous search location or cannot be parsed by name will be deleted.\r\n\r\nNote: _Again, if you get a connection refused you're likely running to many threads for the amount of resources you can utilize (CPU, Memory, and Bandwidth).There will be some pages that may not be able to be processed, and you can delete these bad pages in the table by running the following MySQL statement:_\r\n\r\n`DELETE FROM Facebook.business_pages WHERE name IS NONE;`\r\n\r\n**Mode: 'get' Usage Notes**\r\n\r\nThis mode of operation is multi-threaded, and you should be conscious of your resource limitations (CPU and Network Bandwidth). I recommend running only 10 threads until you know your limitations (i.e. '--threads 10'), and would run this two to three times to ensure you've processed all the information you can before deleting bad pages as described above.\r\n\r\n**Mode: 'get' Usage Example**\r\n\r\n`python /opt/facebook-business-scraper/main.py --mode get --threads 10 --dbip 127.0.0.1 --database Facebook --dbuser root --dbpasswd examplepass`\r\n\r\n####General Usage Information\r\n\r\n`# python /opt/facebook-business-scraper/main.py -h`\r\n\r\n<div id=\"usage\">\r\nusage: usage: main.py [-h] [-l LOCATION] -m MODE [-s SCROLL] [-t THREADS]<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--services SERVICES] -ip DBIP -db DATABASE --dbuser DBUSER<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; --dbpasswd DBPASSWD [--fbuser FBUSER] [--fbpasswd FBPASSWD]<br><br>\r\n\r\nFacebook Business Scraper - https://github.com/Garindan/facebook-business-scraper\r\n\r\n_optional arguments_:<br>\r\n&nbsp;&nbsp; -h, --help<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; show this help message and exit<br>\r\n&nbsp;&nbsp; -l LOCATION, --location LOCATION<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Provide a target location (i.e. Flordia or Miami, Flordia)<br>\r\n&nbsp;&nbsp; -m MODE, --mode MODE<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Gather business pages for associated services (gather) or try to get contact information for pages in table (get)<br>\r\n&nbsp;&nbsp; -s SCROLL, --scroll SCROLL<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Page result scroll limit (i.e. 1000 - the higher the limit the more results you could obtain) which aids in memory management<br>\r\n&nbsp;&nbsp; -t THREADS, --threads THREADS<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Provide the number of threads you'd like to use for getting contact information on pages (i.e. 20)<br>\r\n&nbsp;&nbsp; --services SERVICES  \r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Define a custom service list file (i.e. services.txt)<br>\r\n&nbsp;&nbsp; -ip DATABASE_IP, --dbip DATABASE_IP<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IP address of database (i.e. 127.0.0.1)<br>\r\n&nbsp;&nbsp; -db DATABASE, --database DATABASE<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Provide database name<br>\r\n&nbsp;&nbsp; --dbuser DATABASE_USER<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Provide user login name for the database<br>\r\n&nbsp;&nbsp; --dbpasswd DATABASE_PASSWD<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Provide user login password for the database<br>\r\n&nbsp;&nbsp; --fbuser FACEBOOK_USER<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Provide your facebook Username<br>\r\n&nbsp;&nbsp; --fbpasswd FACEBOOK_PASSWD<br>\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Provide your facebook Username<br>\r\n<div>\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}